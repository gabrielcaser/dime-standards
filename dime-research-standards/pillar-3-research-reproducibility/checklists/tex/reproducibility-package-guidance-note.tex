\input{checklist-header.tex}

% ------------------------------ End of preamble ---------------------------------------------
\begin{document}
	\begin{fullwidth}

\titleBox{
	\textcolor{white}{\LARGE{\textbf{DIME Analytics \\ Reproducibility Check Guidance Note}} \\
	\Large\textbf{{v1.0 - Last updated October 20, 2022}}}
}

	\section*{Reproducibility Check Guidance Note}

	The reproducibility check verifies that the code package as submitted: 

- 	Is stable. It produces identical outputs each time it is run. 
- 	Produces outputs that exactly match the analytical outputs (tables and data visualizations) in the final manuscript, without manual adjustments 

- Creates all the analytical outputs included in the final manuscript

Computational reproducibility is mandatory for all working papers produced by DIME, and encouraged for other research outputs, such as briefs and reports. 


	\bigskip

Reproducibility checks are performed by DIME Analytics. Checks are typically completed within two weeks of submission of a functioning reproducibility package. DIME Analytics prepares a reproducibility review document which highlights any non-reproducible results, problematic practices, and stylistic improvements that would make the code easier to read. 

	\bigskip

	\begin{itemize}
		\setlength\itemsep{-0.1em}
		\item Lack of specification of file or folder paths
		\item Installation of necessary software or packages
		\item Lack of version and matsize settings in Stata
		\item Analytical outputs are created but they are different to how they are presented in the academic publication
		\item Lack of comments in the code to follow through the operations it conducts
	\end{itemize}

	The main task of the review is to make sure that the code runs smoothly in a computer different than where it was developed, and that all the outputs recreated by it exactly match the research outputs shown in the working paper provided.	
DIME Analytics follows specific tasks when conducting the computational reproducibility checks, which are outlined below.

	\subsection{1. \, Receving the reproducibility package}

	The project team will send a code review request via email to DIME Analytics by providing a reproducibility package in a shared OneDrive or Dropbox folder, a GitHub repository, or a compressed folder sent by email if the files size allows. If using a GitHub repository, please share only the code files through GitHub and send the input data files using another channel. The package should contain the items listed below.

	\bigskip

	\begin{itemize}
		\setlength\itemsep{-0.1em}
		\item \textbf{Code:} All scripts necessary to reproduce the analytical outputs of the paper, including a well-documented and well-commented Master Script that allows to perform a one-button run of the code.
		\item \textbf{Data:} Fully de-identified, no access-restricted, and complete data necessary to run the master script that reproduces the outputs (can be raw, clean, or constructed) . Any exception where access to restricted or identified datasets is needed to reproduce code outputs will be handled on a case-by-case basis.
		\item \textbf{Output:} All raw outputs used for the paper (tables and figures), as created by the master script.
	\end{itemize}

	\bigskip

	Note: All the items listed above should be stored in different subfolders in the main project directory.

	\bigskip

	\begin{itemize}
		\setlength\itemsep{-0.1em}
		\item \textbf{Working Paper:} Paper to compare the output generated by the code with the exhibits as presented in the paper.
		\item \textbf{README.txt:} Text file delineating the requirements of the code and datasets included in the package, instructions about the directory structure DIME Analytics should follow, and any ad-hoc instructions to run the master script.
		\item \textbf{Filled-in reproducibility check checklist:} DIME Analytics ask submitting teams to provide \href{https://raw.githubusercontent.com/worldbank/dime-standards/master/dime-research-standards/pillar-3-research-reproducibility/checklists/Reproducibility%20package%20submission%20checklist.pdf}{this checklist} so they can make sure they are submitting all the files needed to run a reproducibility package.
	\end{itemize}

	DIME Analytics will only change the topmost global directory specified in the master script and will run it to reproduce the results â€“ this is what is called a one-button run. The master script code should run without errors after adding the correct folder path of the computer where it will be running. For the paper to be considered fully reproducible, DIME Analytics should reproduce the every exhibit in the paper showing analysis results through this push-button exercise.

	\bigskip

	After receiving a reproducibility package, DIME Analytics will attempt a first one-button run. If the master script breaks, DIME Analytics will identify the point where it is breaking, document it, and attempt to make changes to continue with the review. If the corrections cannot be identified after a 15-minute check, the project team will be notified that further edits are required to conduct the reproducibility check.

	\bigskip

	If the code runs from beginning to end, DIME Analytics will send the team an email confirming that we were able to run the code and providing an estimated time to deliver the results of the review. Reproducibility checks take ten working days (two weeks) in most cases, but might take longer for computationally intensive packages, packages with more than 1 GB of total file size, or when a large volume of submissions is received.

	\bigskip
	
	\begin{center}
		\includegraphics[width=0.9\linewidth]{../img/rep-checks-timeline.png}
	\end{center}

	\subsection{2. \, Reproducibility check}

	After the one-button run works, DIME Analytics will check the following code requirements. The submission should pass all of these checks to be in compliance with DIME Reproducibility Standards.

	\bigskip

	\begin{itemize}
		\setlength\itemsep{-0.1em}
		\item \textbf{Code completeness:} Every paper exhibit containing analysis results should be produced programatically by the code and be a result of statistical analysis. Manual entry of values used in a table or plot, or point-and-click-generated exhibits are not in compliance with DIME Reproducibility Standards.
		\item \textbf{Output stability:} DIME Analytics will run the code between three to five times. Every output should be  identical across each run.
		\item \textbf{Computational reproducibility of tables:} Every statistic of every table needs to be consistent between the outputs produced by the code and the exhibits of the paper. Occasionally, stable marginal differences in point estimates and standard errors might not break adherence with DIME Reproducibility Standards and will be evaluated in a case-by-case basis to determine if they can occur for rounding differences due to hardware or OS specifications.
		\item \textbf{Computational reproducibility of figures:} Every plot needs to be consistent between the code outputs and the paper figures. Differences in graph titles, x and y-axis titles, x and y-ticks, legends, and other style elements might not break adherence to DIME Research Standards, but DIME Analytics will document them in the results report.
	\end{itemize}

	\bigskip
	
	The results of the reproducibility check will be registered in two outputs.

	\bigskip

	\begin{enumerate}
		\setlength\itemsep{-0.1em}
		\item A report detailing the reproducibility status of each paper exhibit along with suggestions to increase code legibility or efficiency. An example can be found \href{https://github.com/worldbank/dime-standards/blob/master/dime-research-standards/pillar-3-research-reproducibility/DIME%20Analytics%20Reproducibility%20Check%20Comments%20example.pdf}{here}.
		\item A checklist with a summary of the results (example \href{https://raw.githubusercontent.com/worldbank/dime-standards/master/dime-research-standards/pillar-3-research-reproducibility/checklists/Reproducibility%20check%20result%20template.pdf}{here}).
	\end{enumerate}

	\bigskip

	\section*{Public release}

	Many journals require data and code to be made publicly available. Once the reproducibility checks are complete and the code and paper meet DIME Reproducibility Standards, DIME Analytics can help to organize a public release of using a repository on the World Bank GitHub (such as \href{https://github.com/worldbank/rio-safe-space}{this example}), the World Bank Microdata Catalog, or the World Bank Development Data Hub.

	\end{fullwidth}
\end{document}
